Random Seed:  999
Generator(
  (main): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace)
    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (12): Sigmoid()
  )
)
Starting Training Loop...
[0/1][0/1583]	Loss_D: 1.7412	Loss_G: 4.7763	D(x): 0.5342	D(G(z)): 0.5771 / 0.0136
[0/1][50/1583]	Loss_D: 0.1204	Loss_G: 8.5105	D(x): 0.9590	D(G(z)): 0.0474 / 0.0004
Traceback (most recent call last):
  File "train.py", line 270, in <module>
    D_G_z2 = output.mean().item()
KeyboardInterrupt
Random Seed:  999
Generator(
  (main): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace)
    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (12): Sigmoid()
  )
)
Starting Training Loop...
[0/1][0/1583]	Loss_D: 1.7412	Loss_G: 4.7764	D(x): 0.5342	D(G(z)): 0.5771 / 0.0136
[0/1][50/1583]	Loss_D: 0.0077	Loss_G: 32.2665	D(x): 0.9933	D(G(z)): 0.0000 / 0.0000
[0/1][100/1583]	Loss_D: 1.6216	Loss_G: 18.8045	D(x): 0.9859	D(G(z)): 0.5334 / 0.0000
[0/1][150/1583]	Loss_D: 1.6204	Loss_G: 5.0222	D(x): 0.3863	D(G(z)): 0.0062 / 0.0147
[0/1][200/1583]	Loss_D: 0.9250	Loss_G: 6.4045	D(x): 0.8539	D(G(z)): 0.4174 / 0.0031
[0/1][250/1583]	Loss_D: 0.4435	Loss_G: 3.8809	D(x): 0.8057	D(G(z)): 0.1340 / 0.0331
[0/1][300/1583]	Loss_D: 0.5842	Loss_G: 3.2523	D(x): 0.7139	D(G(z)): 0.1307 / 0.0549
[0/1][350/1583]	Loss_D: 0.3596	Loss_G: 3.7312	D(x): 0.8084	D(G(z)): 0.0919 / 0.0405
[0/1][400/1583]	Loss_D: 0.6415	Loss_G: 2.8846	D(x): 0.6778	D(G(z)): 0.1265 / 0.0756
[0/1][450/1583]	Loss_D: 0.5649	Loss_G: 5.3841	D(x): 0.9260	D(G(z)): 0.3100 / 0.0131
[0/1][500/1583]	Loss_D: 0.5664	Loss_G: 4.1092	D(x): 0.7259	D(G(z)): 0.0550 / 0.0398
[0/1][550/1583]	Loss_D: 1.7571	Loss_G: 4.4501	D(x): 0.3233	D(G(z)): 0.0013 / 0.0284
[0/1][600/1583]	Loss_D: 0.8613	Loss_G: 7.6470	D(x): 0.9380	D(G(z)): 0.4944 / 0.0012
[0/1][650/1583]	Loss_D: 0.3211	Loss_G: 5.7344	D(x): 0.8715	D(G(z)): 0.1294 / 0.0084
[0/1][700/1583]	Loss_D: 0.4587	Loss_G: 4.9542	D(x): 0.8500	D(G(z)): 0.2079 / 0.0131
[0/1][750/1583]	Loss_D: 0.6190	Loss_G: 6.3005	D(x): 0.9503	D(G(z)): 0.3736 / 0.0034
[0/1][800/1583]	Loss_D: 0.8022	Loss_G: 5.3002	D(x): 0.8029	D(G(z)): 0.3690 / 0.0110
[0/1][850/1583]	Loss_D: 0.2427	Loss_G: 4.0911	D(x): 0.9014	D(G(z)): 0.1081 / 0.0298
[0/1][900/1583]	Loss_D: 0.3639	Loss_G: 5.5821	D(x): 0.7889	D(G(z)): 0.0616 / 0.0073
[0/1][950/1583]	Loss_D: 0.3882	Loss_G: 2.5526	D(x): 0.8506	D(G(z)): 0.1116 / 0.1474
[0/1][1000/1583]	Loss_D: 0.5950	Loss_G: 3.1566	D(x): 0.6757	D(G(z)): 0.0735 / 0.0836
[0/1][1050/1583]	Loss_D: 0.6704	Loss_G: 4.4037	D(x): 0.7899	D(G(z)): 0.2799 / 0.0232
[0/1][1100/1583]	Loss_D: 0.5001	Loss_G: 3.1436	D(x): 0.7927	D(G(z)): 0.1763 / 0.0694
[0/1][1150/1583]	Loss_D: 0.5345	Loss_G: 4.3131	D(x): 0.8203	D(G(z)): 0.2239 / 0.0259
[0/1][1200/1583]	Loss_D: 0.3806	Loss_G: 4.0488	D(x): 0.8119	D(G(z)): 0.0721 / 0.0328
[0/1][1250/1583]	Loss_D: 0.8068	Loss_G: 5.6100	D(x): 0.9373	D(G(z)): 0.4507 / 0.0090
[0/1][1300/1583]	Loss_D: 0.3247	Loss_G: 4.5515	D(x): 0.9222	D(G(z)): 0.1977 / 0.0166
[0/1][1350/1583]	Loss_D: 0.4931	Loss_G: 2.8247	D(x): 0.8256	D(G(z)): 0.1825 / 0.0991
[0/1][1400/1583]	Loss_D: 0.9077	Loss_G: 6.6288	D(x): 0.9373	D(G(z)): 0.4874 / 0.0039
[0/1][1450/1583]	Loss_D: 0.4880	Loss_G: 3.1068	D(x): 0.7462	D(G(z)): 0.1213 / 0.0738
[0/1][1500/1583]	Loss_D: 0.4422	Loss_G: 3.2100	D(x): 0.7851	D(G(z)): 0.1446 / 0.0652
[0/1][1550/1583]	Loss_D: 0.3135	Loss_G: 3.2695	D(x): 0.8414	D(G(z)): 0.1058 / 0.0561
